{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Imbalance Sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "# Pipelines imports\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import GenericUnivariateSelect,f_regression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# Scoring function\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "#from scipy import signal\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import sequence \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Bidirectional, MaxPooling1D\n",
    "\n",
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 1000)\n",
      "(4800,)\n",
      "[ 600 3600  600]\n",
      "(1200, 1000)\n",
      "(3600, 1000)\n",
      "(1200,)\n",
      "(3600,)\n",
      "(600, 1000)\n",
      "(600,)\n",
      "(10800, 1000)\n",
      "(10800,)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "Xdf = pd.read_csv(\"X_train.csv\")\n",
    "XTestdf = pd.read_csv(\"X_test.csv\")\n",
    "ydf = pd.read_csv(\"y_train.csv\")\n",
    "X = Xdf[Xdf.columns[1:]].values\n",
    "Xtest = XTestdf[XTestdf.columns[1:]].values\n",
    "y = ydf[ydf.columns[1]].values\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Accounting for imbalance in the data\n",
    "oversample = True\n",
    "if oversample:\n",
    "    # Random Oversampler\n",
    "    #ros = RandomOverSampler(random_state=42)\n",
    "    #X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    \n",
    "    # Smote oversampler\n",
    "    X, y = SMOTE().fit_resample(X, y)\n",
    "    \n",
    "    # Adasyn oversampler\n",
    "    #X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
    "else:\n",
    "    # Count number of occurances per class\n",
    "    _, counts = np.unique(y,return_counts=True)\n",
    "    print(counts)\n",
    "\n",
    "    # Divide by class \n",
    "    X0 = X[y != 1]\n",
    "    X1 = X[y == 1]\n",
    "    y0 = y[y != 1]\n",
    "    y1 = y[y == 1]\n",
    "    print(X0.shape)\n",
    "    print(X1.shape)\n",
    "    print(y0.shape)\n",
    "    print(y1.shape)\n",
    "\n",
    "    # Downsampling\n",
    "    indices_subsampled = np.random.RandomState(seed=42).choice(range(X1.shape[0]),int(counts[0]),replace=False)\n",
    "    X1_subsampled = X1[indices_subsampled]\n",
    "    y1_subsampled = y1[indices_subsampled]\n",
    "    print(X1_subsampled.shape)\n",
    "    print(y1_subsampled.shape)\n",
    "\n",
    "    X = np.concatenate((X0,X1_subsampled))\n",
    "    y = np.concatenate((y0,y1_subsampled))\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.RandomState(seed=42).permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "X,y = unison_shuffled_copies(X,y)\n",
    "\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    y = np_utils.to_categorical(y)\n",
    "    \n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get best estimator\n",
    "def get_best_estimator(pipeline, X, y, parameters, scoring, cv=5, verbose=0, n_jobs=None):\n",
    "    print('Finding best parameters through grid search...')\n",
    "    grid = GridSearchCV(pipeline, param_grid=parameters, scoring=scoring, cv=cv, verbose=verbose, refit=True, return_train_score=False, n_jobs=n_jobs)\n",
    "    grid.fit(X, y)\n",
    "    print('Done!')\n",
    "    return grid.best_estimator_, grid\n",
    "\n",
    "def find_best(pipeline, X, y, parameters, scoring, cv=5, verbose=0, n_jobs=None):\n",
    "    best_pipeline, grid = get_best_estimator(pipeline, X, y, parameters, scoring, cv=cv, verbose=verbose, n_jobs=n_jobs)\n",
    "    return grid\n",
    "\n",
    "# If you want to revert 1-hot encoding after classifier in the sklearn pipeline. NOT SURE IF IT WORKS\n",
    "class Revert1Hot(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return np.argmax(X)\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters through grid search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  6.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "score = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# Different classifiers that need to be tested\n",
    "#classifiers = [\n",
    "#    KNeighborsClassifier(3),\n",
    "#    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "#    NuSVC(probability=True),\n",
    "#    DecisionTreeClassifier(),\n",
    "#    RandomForestClassifier(),\n",
    "#    AdaBoostClassifier(),\n",
    "#    GradientBoostingClassifier()\n",
    "#    ]\n",
    "\n",
    "steps = [\n",
    "    \n",
    "    ('scaler', StandardScaler()), \n",
    "    ('ufs',GenericUnivariateSelect(score_func=f_regression, mode='k_best', param=200)),\n",
    "    ('XGB', OneVsRestClassifier(xgboost.XGBClassifier(colsample_bytree=0.6,\n",
    "                                                      min_child_weight=6,\n",
    "                                                      max_depth=8)))\n",
    "     ]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'ufs__param':[1000]}\n",
    "\n",
    "\n",
    "grid = find_best(pipeline, X, y, parameters, score, cv=3, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238.078083</td>\n",
       "      <td>0.38562</td>\n",
       "      <td>{'ufs__param': 1000}</td>\n",
       "      <td>0.93037</td>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time                params  mean_test_score  \\\n",
       "0     238.078083          0.38562  {'ufs__param': 1000}          0.93037   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.003088  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_fit_time','mean_score_time','params','mean_test_score','std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline.fit does not accept the scoring parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-637eee713b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;34m\"pipeline using the stepname__parameter format, e.g. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0;34m\"`Pipeline.fit(X, y, logisticregression__sample_weight\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                     \"=sample_weight)`.\".format(pname))\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pipeline.fit does not accept the scoring parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`."
     ]
    }
   ],
   "source": [
    "# Still not sure how to extract best model from GridSearch and predict it for the test set\n",
    "pipeline.fit(X,y,scoring=score)\n",
    "result = pipeline.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not very promising as it only reaches 66.83% accuracy. \n",
    "# Maybe try to use convolutional network although doubting that could help.\n",
    "def create_model():\n",
    "    num_features=1000\n",
    "    mid_size=100\n",
    "    dropout=0.1\n",
    "    \n",
    "    # Model Definition\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_features, activation=\"relu\", input_shape=(num_features,)))\n",
    "    # model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(1000,)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(200, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], \n",
    "                  weighted_metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#Define Early stopping mechanism\n",
    "es = EarlyStopping(monitor='val_loss', mode='max', patience=5, verbose=1)\n",
    "\n",
    "# wrap the model using the function you created   , callbacks=[es]\n",
    "clf = KerasClassifier(build_fn=create_model, epochs=20, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,213,953\n",
      "Trainable params: 1,213,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.8816 - acc: 0.6067 - weighted_acc: 0.6067\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.7491 - acc: 0.6608 - weighted_acc: 0.6608\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.6487 - acc: 0.7217 - weighted_acc: 0.7217\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.5879 - acc: 0.7583 - weighted_acc: 0.7583\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.4746 - acc: 0.8100 - weighted_acc: 0.8100\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.4193 - acc: 0.8325 - weighted_acc: 0.8325\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.3267 - acc: 0.8742 - weighted_acc: 0.8742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3095 - acc: 0.8992 - weighted_acc: 0.8992\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2154 - acc: 0.9158 - weighted_acc: 0.9158\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 5s 5ms/step - loss: 0.1173 - acc: 0.9633 - weighted_acc: 0.9633\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1289 - acc: 0.9583 - weighted_acc: 0.9583\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1320 - acc: 0.9592 - weighted_acc: 0.9592\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2678 - acc: 0.9325 - weighted_acc: 0.9325\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1141 - acc: 0.9675 - weighted_acc: 0.9675\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0899 - acc: 0.9750 - weighted_acc: 0.9750\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0443 - acc: 0.9858 - weighted_acc: 0.9858\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0107 - acc: 0.9992 - weighted_acc: 0.9992\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1065 - acc: 0.9708 - weighted_acc: 0.9708\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0765 - acc: 0.9733 - weighted_acc: 0.9733\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1442 - acc: 0.9758 - weighted_acc: 0.9758\n",
      "600/600 [==============================] - 0s 797us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,213,953\n",
      "Trainable params: 1,213,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 7s 5ms/step - loss: 0.8665 - acc: 0.6008 - weighted_acc: 0.6008\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.7366 - acc: 0.6808 - weighted_acc: 0.6808\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.6470 - acc: 0.7292 - weighted_acc: 0.7292\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.5534 - acc: 0.7667 - weighted_acc: 0.7667\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4593 - acc: 0.8225 - weighted_acc: 0.8225\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3662 - acc: 0.8567 - weighted_acc: 0.8567\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3310 - acc: 0.8842 - weighted_acc: 0.8842\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2695 - acc: 0.9067 - weighted_acc: 0.9067\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.2286 - acc: 0.9150 - weighted_acc: 0.9150\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1737 - acc: 0.9417 - weighted_acc: 0.9417\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.1440 - acc: 0.9500 - weighted_acc: 0.9500\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 7s 5ms/step - loss: 0.0940 - acc: 0.9692 - weighted_acc: 0.9692\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0633 - acc: 0.9783 - weighted_acc: 0.9783\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0565 - acc: 0.9867 - weighted_acc: 0.9867\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1513 - acc: 0.9550 - weighted_acc: 0.9550\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0535 - acc: 0.9833 - weighted_acc: 0.9833\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.1254 - acc: 0.9667 - weighted_acc: 0.9667\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0617 - acc: 0.9808 - weighted_acc: 0.9808\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0699 - acc: 0.9783 - weighted_acc: 0.9783\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0876 - acc: 0.9817 - weighted_acc: 0.9817\n",
      "600/600 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,213,953\n",
      "Trainable params: 1,213,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.9259 - acc: 0.5742 - weighted_acc: 0.5742\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.8024 - acc: 0.6300 - weighted_acc: 0.6300\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.7126 - acc: 0.7008 - weighted_acc: 0.7008\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.6379 - acc: 0.7325 - weighted_acc: 0.7325\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.5394 - acc: 0.7750 - weighted_acc: 0.7750\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4467 - acc: 0.8325 - weighted_acc: 0.8325\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3835 - acc: 0.8542 - weighted_acc: 0.8542\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.3586 - acc: 0.8792 - weighted_acc: 0.8792\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2453 - acc: 0.9200 - weighted_acc: 0.9200\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1732 - acc: 0.9375 - weighted_acc: 0.9375\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1643 - acc: 0.9533 - weighted_acc: 0.9533\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1033 - acc: 0.9725 - weighted_acc: 0.9725\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2366 - acc: 0.9375 - weighted_acc: 0.9375\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1120 - acc: 0.9683 - weighted_acc: 0.9683\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 7s 5ms/step - loss: 0.0726 - acc: 0.9850 - weighted_acc: 0.9850\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0680 - acc: 0.9850 - weighted_acc: 0.9850\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0775 - acc: 0.9817 - weighted_acc: 0.9817\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1147 - acc: 0.9642 - weighted_acc: 0.9642\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0677 - acc: 0.9817 - weighted_acc: 0.9817\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0183 - acc: 0.9992 - weighted_acc: 0.9992\n",
      "600/600 [==============================] - 1s 1ms/step\n",
      "Baseline: 66.83% (2.66%)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(clf, X, y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. '<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa114fe2320>' (type <class 'keras.wrappers.scikit_learn.KerasClassifier'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-31cb255adcac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m      ]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#parameters = [{'ufs__param':[200], 'clf__features':[200], 'clf__mid_size':[50, 10]},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml4h/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml4h/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[1;32m    166\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. '<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa114fe2320>' (type <class 'keras.wrappers.scikit_learn.KerasClassifier'>) doesn't"
     ]
    }
   ],
   "source": [
    "score = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "# Having difficulties adding the tensorflow deep learning model to the sklearn pipeline. \n",
    "# It complains about the keras classifier not having a transform function although it is used in this way in tutorials. \n",
    "# Maybe I have a mistake somewhere.\n",
    "steps = [\n",
    "    \n",
    "    ('scaler', StandardScaler()), \n",
    "    ('ufs',GenericUnivariateSelect(score_func=f_regression, mode='k_best', param=200)),\n",
    "    ('clf', clf),\n",
    "    ('revert1hot', Revert1Hot())\n",
    "     ]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#parameters = [{'ufs__param':[200], 'clf__features':[200], 'clf__mid_size':[50, 10]},\n",
    "#             {'ufs__param':[500], 'clf__features':[500], 'clf__mid_size':[100, 20]},\n",
    "#             {'ufs__param':[1000], 'clf__features':[1000], 'clf__mid_size':[200, 100]},]\n",
    "\n",
    "parameters = {'ufs__param':[200], 'clf__features':[200], 'clf__mid_size':[50]}\n",
    "              \n",
    "grid = find_best(pipeline, X, y, parameters, score, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "pandas.DataFrame(grid.cv_results_)[['mean_fit_time','mean_score_time','params','mean_test_score','std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
