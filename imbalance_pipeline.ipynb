{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Imbalance Sampling\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "\n",
    "# Pipelines imports\n",
    "import xgboost\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import GenericUnivariateSelect,f_regression\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "# Scoring function\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "#from scipy import signal\n",
    "\n",
    "# Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import sequence \n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, GlobalAveragePooling1D, Bidirectional, MaxPooling1D\n",
    "\n",
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 1000)\n",
      "(4800,)\n",
      "[ 600 3600  600]\n",
      "(1200, 1000)\n",
      "(3600, 1000)\n",
      "(1200,)\n",
      "(3600,)\n",
      "(600, 1000)\n",
      "(600,)\n",
      "(10800, 1000)\n",
      "(10800,)\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "Xdf = pd.read_csv(\"X_train.csv\")\n",
    "XTestdf = pd.read_csv(\"X_test.csv\")\n",
    "ydf = pd.read_csv(\"y_train.csv\")\n",
    "X = Xdf[Xdf.columns[1:]].values\n",
    "Xtest = XTestdf[XTestdf.columns[1:]].values\n",
    "y = ydf[ydf.columns[1]].values\n",
    "\n",
    "# Random Oversampler\n",
    "Oversample = True\n",
    "#ros = RandomOverSampler(random_state=42)\n",
    "#X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(X, y)\n",
    "#X_resampled, y_resampled = ADASYN().fit_resample(X, y)\n",
    "\n",
    "# encode class values as integers (Already in interger form)\n",
    "#encoder = LabelEncoder()\n",
    "#encoder.fit(y)\n",
    "#encoded_y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "one_hot = False\n",
    "if one_hot:\n",
    "    y = np_utils.to_categorical(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.RandomState(seed=42).permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "# Count number of occurances per class\n",
    "if one_hot:\n",
    "    counts = np.sum(y,axis=0, dtype=int)\n",
    "else:\n",
    "    _, counts = np.unique(y,return_counts=True)\n",
    "print(counts)\n",
    "\n",
    "# Divide by class\n",
    "if one_hot:\n",
    "    X0 = X[y[:, 1] != 1]\n",
    "    X1 = X[y[:, 1] == 1]\n",
    "    y0 = y[y[:, 1] != 1]\n",
    "    y1 = y[y[:, 1] == 1]\n",
    "else:     \n",
    "    X0 = X[y != 1]\n",
    "    X1 = X[y == 1]\n",
    "    y0 = y[y != 1]\n",
    "    y1 = y[y == 1]\n",
    "print(X0.shape)\n",
    "print(X1.shape)\n",
    "print(y0.shape)\n",
    "print(y1.shape)\n",
    "\n",
    "# Downsampling\n",
    "indices_subsampled = np.random.RandomState(seed=42).choice(range(X1.shape[0]),int(counts[0]),replace=False)\n",
    "X1_subsampled = X1[indices_subsampled]\n",
    "y1_subsampled = y1[indices_subsampled]\n",
    "print(X1_subsampled.shape)\n",
    "print(y1_subsampled.shape)\n",
    "    \n",
    "X = np.concatenate((X0,X1_subsampled))\n",
    "y = np.concatenate((y0,y1_subsampled))\n",
    "\n",
    "if Oversample:\n",
    "    X = X_resampled\n",
    "    y = y_resampled\n",
    "    \n",
    "X,y = unison_shuffled_copies(X,y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get best estimator\n",
    "def get_best_estimator(pipeline, X, y, parameters, scoring, cv=5, verbose=0, n_jobs=None):\n",
    "    print('Finding best parameters through grid search...')\n",
    "    grid = GridSearchCV(pipeline, param_grid=parameters, scoring=scoring, cv=cv, verbose=verbose, refit=True, return_train_score=False, n_jobs=n_jobs)\n",
    "    grid.fit(X, y)\n",
    "    print('Done!')\n",
    "    return grid.best_estimator_, grid\n",
    "\n",
    "def find_best(pipeline, X, y, parameters, scoring, cv=5, verbose=0, n_jobs=None):\n",
    "    best_pipeline, grid = get_best_estimator(pipeline, X, y, parameters, scoring, cv=cv, verbose=verbose, n_jobs=n_jobs)\n",
    "    return grid\n",
    "\n",
    "class Revert1Hot(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return np.argmax(X)\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding best parameters through grid search...\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'y_true'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 418, in _process_worker\n    r = call_item()\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py\", line 272, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 567, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 516, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/pipeline.py\", line 356, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/multiclass.py\", line 216, in fit\n    for i, column in enumerate(columns))\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 921, in __call__\n    if self.dispatch_one_batch(iterator):\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 759, in dispatch_one_batch\n    self._dispatch(tasks)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 716, in _dispatch\n    job = self._backend.apply_async(batch, callback=cb)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 182, in apply_async\n    result = ImmediateResult(func)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\", line 549, in __init__\n    self.results = batch()\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in __call__\n    for func, args, kwargs in self.items]\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\", line 225, in <listcomp>\n    for func, args, kwargs in self.items]\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/multiclass.py\", line 80, in _fit_binary\n    estimator.fit(X, y)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/sklearn.py\", line 732, in fit\n    callbacks=callbacks)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/training.py\", line 216, in train\n    xgb_model=xgb_model, callbacks=callbacks)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/training.py\", line 74, in _train_internal\n    bst.update(dtrain, i, obj)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/core.py\", line 1112, in update\n    grad, hess = fobj(pred, dtrain)\n  File \"/home/leopold/anaconda3/envs/ml/lib/python3.7/site-packages/xgboost/sklearn.py\", line 49, in inner\n    return func(labels, preds)\nTypeError: __call__() missing 1 required positional argument: 'y_true'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-94a1f538d0d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-6fe6d67a9e96>\u001b[0m in \u001b[0;36mfind_best\u001b[0;34m(pipeline, X, y, parameters, scoring, cv, verbose, n_jobs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_best\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbest_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-6fe6d67a9e96>\u001b[0m in \u001b[0;36mget_best_estimator\u001b[0;34m(pipeline, X, y, parameters, scoring, cv, verbose, n_jobs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Finding best parameters through grid search...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    433\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'y_true'"
     ]
    }
   ],
   "source": [
    "score = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "#classifiers = [\n",
    "#    KNeighborsClassifier(3),\n",
    "#    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "#    NuSVC(probability=True),\n",
    "#    DecisionTreeClassifier(),\n",
    "#    RandomForestClassifier(),\n",
    "#    AdaBoostClassifier(),\n",
    "#    GradientBoostingClassifier()\n",
    "#    ]\n",
    "\n",
    "steps = [\n",
    "    \n",
    "    ('scaler', StandardScaler()), \n",
    "    ('ufs',GenericUnivariateSelect(score_func=f_regression, mode='k_best', param=200)),\n",
    "    ('XGB', OneVsRestClassifier(xgboost.XGBClassifier(objective=score,\n",
    "                                                      colsample_bytree=0.6,\n",
    "                                                      min_child_weight=6,\n",
    "                                                      max_depth=8)))\n",
    "     ]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "parameters = {'ufs__param':[1000]}\n",
    "\n",
    "\n",
    "grid = find_best(pipeline, X, y, parameters, score, cv=3, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>238.078083</td>\n",
       "      <td>0.38562</td>\n",
       "      <td>{'ufs__param': 1000}</td>\n",
       "      <td>0.93037</td>\n",
       "      <td>0.003088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time                params  mean_test_score  \\\n",
       "0     238.078083          0.38562  {'ufs__param': 1000}          0.93037   \n",
       "\n",
       "   std_test_score  \n",
       "0        0.003088  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['mean_fit_time','mean_score_time','params','mean_test_score','std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline.fit does not accept the scoring parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-637eee713b22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m--> 352\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[1;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;34m\"pipeline using the stepname__parameter format, e.g. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m                     \u001b[0;34m\"`Pipeline.fit(X, y, logisticregression__sample_weight\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                     \"=sample_weight)`.\".format(pname))\n\u001b[0m\u001b[1;32m    282\u001b[0m             \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Pipeline.fit does not accept the scoring parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`."
     ]
    }
   ],
   "source": [
    "pipeline.fit(X,y,scoring=score)\n",
    "result = pipeline.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    num_features=1000\n",
    "    mid_size=100\n",
    "    dropout=0.1\n",
    "    \n",
    "    # Model Definition\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_features, activation=\"relu\", input_shape=(num_features,)))\n",
    "    # model.add(Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=(1000,)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(200, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(50, activation=\"relu\"))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(3, activation=\"softmax\"))\n",
    "\n",
    "    #compile model using accuracy to measure model performance\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], \n",
    "                  weighted_metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#Define Early stopping mechanism\n",
    "es = EarlyStopping(monitor='val_loss', mode='max', patience=5, verbose=1)\n",
    "\n",
    "# wrap the model using the function you created   , callbacks=[es]\n",
    "clf = KerasClassifier(build_fn=create_model, epochs=20, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,213,953\n",
      "Trainable params: 1,213,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.8816 - acc: 0.6067 - weighted_acc: 0.6067\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.7491 - acc: 0.6608 - weighted_acc: 0.6608\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.6487 - acc: 0.7217 - weighted_acc: 0.7217\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.5879 - acc: 0.7583 - weighted_acc: 0.7583\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.4746 - acc: 0.8100 - weighted_acc: 0.8100\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.4193 - acc: 0.8325 - weighted_acc: 0.8325\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.3267 - acc: 0.8742 - weighted_acc: 0.8742\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3095 - acc: 0.8992 - weighted_acc: 0.8992\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.2154 - acc: 0.9158 - weighted_acc: 0.9158\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 5s 5ms/step - loss: 0.1173 - acc: 0.9633 - weighted_acc: 0.9633\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1289 - acc: 0.9583 - weighted_acc: 0.9583\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1320 - acc: 0.9592 - weighted_acc: 0.9592\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2678 - acc: 0.9325 - weighted_acc: 0.9325\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1141 - acc: 0.9675 - weighted_acc: 0.9675\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0899 - acc: 0.9750 - weighted_acc: 0.9750\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0443 - acc: 0.9858 - weighted_acc: 0.9858\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0107 - acc: 0.9992 - weighted_acc: 0.9992\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1065 - acc: 0.9708 - weighted_acc: 0.9708\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0765 - acc: 0.9733 - weighted_acc: 0.9733\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.1442 - acc: 0.9758 - weighted_acc: 0.9758\n",
      "600/600 [==============================] - 0s 797us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_53 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,213,953\n",
      "Trainable params: 1,213,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 7s 5ms/step - loss: 0.8665 - acc: 0.6008 - weighted_acc: 0.6008\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.7366 - acc: 0.6808 - weighted_acc: 0.6808\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.6470 - acc: 0.7292 - weighted_acc: 0.7292\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.5534 - acc: 0.7667 - weighted_acc: 0.7667\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4593 - acc: 0.8225 - weighted_acc: 0.8225\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3662 - acc: 0.8567 - weighted_acc: 0.8567\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.3310 - acc: 0.8842 - weighted_acc: 0.8842\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2695 - acc: 0.9067 - weighted_acc: 0.9067\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.2286 - acc: 0.9150 - weighted_acc: 0.9150\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1737 - acc: 0.9417 - weighted_acc: 0.9417\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.1440 - acc: 0.9500 - weighted_acc: 0.9500\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 7s 5ms/step - loss: 0.0940 - acc: 0.9692 - weighted_acc: 0.9692\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0633 - acc: 0.9783 - weighted_acc: 0.9783\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.0565 - acc: 0.9867 - weighted_acc: 0.9867\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1513 - acc: 0.9550 - weighted_acc: 0.9550\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0535 - acc: 0.9833 - weighted_acc: 0.9833\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.1254 - acc: 0.9667 - weighted_acc: 0.9667\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.0617 - acc: 0.9808 - weighted_acc: 0.9808\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.0699 - acc: 0.9783 - weighted_acc: 0.9783\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.0876 - acc: 0.9817 - weighted_acc: 0.9817\n",
      "600/600 [==============================] - 1s 2ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_58 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 200)               200200    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 50)                10050     \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 3)                 153       \n",
      "=================================================================\n",
      "Total params: 1,213,953\n",
      "Trainable params: 1,213,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 11s 9ms/step - loss: 0.9259 - acc: 0.5742 - weighted_acc: 0.5742\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.8024 - acc: 0.6300 - weighted_acc: 0.6300\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.7126 - acc: 0.7008 - weighted_acc: 0.7008\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.6379 - acc: 0.7325 - weighted_acc: 0.7325\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.5394 - acc: 0.7750 - weighted_acc: 0.7750\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.4467 - acc: 0.8325 - weighted_acc: 0.8325\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.3835 - acc: 0.8542 - weighted_acc: 0.8542\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.3586 - acc: 0.8792 - weighted_acc: 0.8792\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2453 - acc: 0.9200 - weighted_acc: 0.9200\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1732 - acc: 0.9375 - weighted_acc: 0.9375\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.1643 - acc: 0.9533 - weighted_acc: 0.9533\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1033 - acc: 0.9725 - weighted_acc: 0.9725\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2366 - acc: 0.9375 - weighted_acc: 0.9375\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1120 - acc: 0.9683 - weighted_acc: 0.9683\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 7s 5ms/step - loss: 0.0726 - acc: 0.9850 - weighted_acc: 0.9850\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0680 - acc: 0.9850 - weighted_acc: 0.9850\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.0775 - acc: 0.9817 - weighted_acc: 0.9817\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.1147 - acc: 0.9642 - weighted_acc: 0.9642\n",
      "Epoch 19/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.0677 - acc: 0.9817 - weighted_acc: 0.9817\n",
      "Epoch 20/20\n",
      "1200/1200 [==============================] - 5s 4ms/step - loss: 0.0183 - acc: 0.9992 - weighted_acc: 0.9992\n",
      "600/600 [==============================] - 1s 1ms/step\n",
      "Baseline: 66.83% (2.66%)\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(clf, X, y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform. '<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa114fe2320>' (type <class 'keras.wrappers.scikit_learn.KerasClassifier'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-31cb255adcac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m      ]\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#parameters = [{'ufs__param':[200], 'clf__features':[200], 'clf__mid_size':[50, 10]},\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml4h/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml4h/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[1;32m    166\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                                 \" '%s' (type %s) doesn't\" % (t, type(t)))\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# We allow last estimator to be None as an identity transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform. '<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fa114fe2320>' (type <class 'keras.wrappers.scikit_learn.KerasClassifier'>) doesn't"
     ]
    }
   ],
   "source": [
    "score = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "steps = [\n",
    "    \n",
    "    ('scaler', StandardScaler()), \n",
    "    ('ufs',GenericUnivariateSelect(score_func=f_regression, mode='k_best', param=200)),\n",
    "    ('clf', clf),\n",
    "    ('revert1hot', Revert1Hot())\n",
    "     ]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#parameters = [{'ufs__param':[200], 'clf__features':[200], 'clf__mid_size':[50, 10]},\n",
    "#             {'ufs__param':[500], 'clf__features':[500], 'clf__mid_size':[100, 20]},\n",
    "#             {'ufs__param':[1000], 'clf__features':[1000], 'clf__mid_size':[200, 100]},]\n",
    "\n",
    "parameters = {'ufs__param':[200], 'clf__features':[200], 'clf__mid_size':[50]}\n",
    "              \n",
    "grid = find_best(pipeline, X, y, parameters, score, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "pandas.DataFrame(grid.cv_results_)[['mean_fit_time','mean_score_time','params','mean_test_score','std_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
